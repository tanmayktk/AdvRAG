{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your doc\n",
    "from langchain_community.document_loaders import PyPDFLoader, CSVLoader, DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(\"data\", glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TanmayRaju\\miniconda3\\envs\\genchatbot\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\TanmayRaju\\miniconda3\\envs\\genchatbot\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\TanmayRaju\\miniconda3\\envs\\genchatbot\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Instantaniate embedding\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantaniate LLM\n",
    "from langchain_community.chat_models import ChatDatabricks\n",
    "\n",
    "chat_llm = ChatDatabricks(endpoint=\"databricks-dbrx-instruct\", max_tokens=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254\n"
     ]
    }
   ],
   "source": [
    "# Document Splitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1250,\n",
    "    chunk_overlap = 100,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False\n",
    ")\n",
    "#\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "print(len(split_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TanmayRaju\\miniconda3\\envs\\genchatbot\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Instantaniate Vectorstore\n",
    "from langchain_community.vectorstores import Chroma\n",
    "vectorstore = Chroma(embedding_function=embeddings,\n",
    "                     persist_directory=\"/content/drive/MyDrive/Vectorstore/chromadb\",\n",
    "                     collection_name=\"full_documents\")\n",
    "# Load and persist the split documents into the vectorstore\n",
    "vectorstore.add_documents(split_docs)\n",
    "vectorstore.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Keyword / Sparse embeddings model\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "#\n",
    "bm25_retriever = BM25Retriever.from_documents(split_docs)\n",
    "bm25_retriever.k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TanmayRaju\\miniconda3\\envs\\genchatbot\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Reranker — Cross Encoders\n",
    "from __future__ import annotations\n",
    "from typing import Dict, Optional, Sequence\n",
    "from langchain.schema import Document\n",
    "from langchain.pydantic_v1 import Extra, root_validator\n",
    "\n",
    "from langchain.callbacks.manager import Callbacks\n",
    "from langchain.retrievers.document_compressors.base import BaseDocumentCompressor\n",
    "\n",
    "from sentence_transformers import CrossEncoder\n",
    "# from config import bge_reranker_large\n",
    "\n",
    "class BgeRerank(BaseDocumentCompressor):\n",
    "    model_name:str = 'BAAI/bge-reranker-large'\n",
    "    \"\"\"Model name to use for reranking.\"\"\"\n",
    "    top_n: int = 3\n",
    "    \"\"\"Number of documents to return.\"\"\"\n",
    "    model:CrossEncoder = CrossEncoder(model_name)\n",
    "    \"\"\"CrossEncoder instance to use for reranking.\"\"\"\n",
    "\n",
    "    def bge_rerank(self,query,docs):\n",
    "        model_inputs =  [[query, doc] for doc in docs]\n",
    "        scores = self.model.predict(model_inputs)\n",
    "        results = sorted(enumerate(scores), key=lambda x: x[1], reverse=True)\n",
    "        return results[:self.top_n]\n",
    "\n",
    "\n",
    "    class Config:\n",
    "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
    "\n",
    "        extra = Extra.forbid\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def compress_documents(\n",
    "        self,\n",
    "        documents: Sequence[Document],\n",
    "        query: str,\n",
    "        callbacks: Optional[Callbacks] = None,\n",
    "    ) -> Sequence[Document]:\n",
    "        \"\"\"\n",
    "        Compress documents using BAAI/bge-reranker models.\n",
    "\n",
    "        Args:\n",
    "            documents: A sequence of documents to compress.\n",
    "            query: The query to use for compressing the documents.\n",
    "            callbacks: Callbacks to run during the compression process.\n",
    "\n",
    "        Returns:\n",
    "            A sequence of compressed documents.\n",
    "        \"\"\"\n",
    "        if len(documents) == 0:  # to avoid empty api call\n",
    "            return []\n",
    "        doc_list = list(documents)\n",
    "        _docs = [d.page_content for d in doc_list]\n",
    "        results = self.bge_rerank(query, _docs)\n",
    "        final_results = []\n",
    "        for r in results:\n",
    "            doc = doc_list[r[0]]\n",
    "            doc.metadata[\"relevance_score\"] = r[1]\n",
    "            final_results.append(doc)\n",
    "        return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Contextual Compression Pipeline\n",
    "from langchain_community.document_transformers.embeddings_redundant_filter import EmbeddingsRedundantFilter\n",
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_community.document_transformers.long_context_reorder import LongContextReorder\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "#\n",
    "vs_retriever = vectorstore.as_retriever(search_kwargs={\"k\":10})\n",
    "#\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever,vs_retriever],\n",
    "                                       weight=[0.5,0.5])\n",
    "#\n",
    "\n",
    "redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings)\n",
    "#\n",
    "reordering = LongContextReorder()\n",
    "#\n",
    "reranker = BgeRerank()\n",
    "#\n",
    "pipeline_compressor = DocumentCompressorPipeline(transformers=[redundant_filter,reordering,reranker])\n",
    "#\n",
    "compression_pipeline = ContextualCompressionRetriever(base_compressor=pipeline_compressor,\n",
    "                                                      base_retriever=ensemble_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      " + 2023.\n",
      "[544] N. Gillibrand and C. Draper, “Informational sovereignty: A\n",
      "new framework for ai regulation,” Gillibrand, Nicky, and Chris\n",
      "Draper.“Informational Sovereignty: A New Framework For AI Reg-\n",
      "ulation”(July 17, 2023). , 2023.\n",
      "[545] D. Oba, M. Kaneko, and D. Bollegala, “In-contextual bias suppression\n",
      "for large language models,” arXiv preprint arXiv:2309.07251 , 2023.\n",
      "[546] Z. Ji, N. Lee, R. Frieske, T. Yu, D. Su, Y . Xu, E. Ishii, Y . J. Bang,\n",
      "A. Madotto, and P. Fung, “Survey of hallucination in natural language\n",
      "generation,” ACM Computing Surveys , vol. 55, no. 12, pp. 1–38, 2023.\n",
      "[547] J. Greene, “Will ChatGPT Make Lawyers Obsolete? (Hint: Be Afraid),”\n",
      "Reuters , December 2022.\n",
      "[548] T. McCoy, E. Pavlick, and T. Linzen, “Right for the wrong reasons:\n",
      "Diagnosing syntactic heuristics in natural language inference,” in\n",
      "Proceedings of the 57th Annual Meeting of the Association for Compu-\n",
      "tational Linguistics , (Florence, Italy), pp. 3428–3448, Association for\n",
      "Computational Linguistics, July 2019.\n",
      "[549] J. Weston, E. Dinan, and A. Miller, “Retrieve and refine: Improved\n",
      "sequence generation models for dialogue,” in Proceedings of the\n",
      "2018 EMNLP Workshop SCAI: The 2nd International Workshop on\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      " + For instance, if the model is trained to optimize for a\n",
      "specific metric, such as accuracy or engagement, it may\n",
      "prioritize generating responses that align with that metric,\n",
      "even if those responses are biased in some way. (iv)\n",
      "Contextual bias: Chatbots generate responses based on\n",
      "the context provided by users. If the context contains\n",
      "bias associated with factors like the user’s location or\n",
      "language, the model may generate biased responses [545].\n",
      "•Information Hallucination: Hallucination in Natural\n",
      "Language Generation (NLG) is the generation of text\n",
      "that is nonsensical or unfaithful to the provided source\n",
      "content [546]. Hallucinations in LLMs are often the result\n",
      "of the model’s attempt to fill in gaps in knowledge or\n",
      "context, with assumptions that are based on the patterns\n",
      "it has learned during training. This can lead to incorrect or\n",
      "misleading outputs, which can be particularly problematic\n",
      "in sensitive applications [390].\n",
      "The cause of hallucinations in LLMs is an area of active\n",
      "research. Recent advances suggest that it’s a complex\n",
      "problem related to the model’s training process, dataset,\n",
      "and architectural design [547]. In particular, LLMs might\n",
      "be biased towards producing more \"interesting\" or fluent\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      " + be biased towards producing more \"interesting\" or fluent\n",
      "outputs, leading to a higher risk of hallucination [548].\n"
     ]
    }
   ],
   "source": [
    "# Helper function to display retrieved documents\n",
    "def pretty_print_docs(docs):\n",
    "  print(\n",
    "      f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n + {d.page_content}\" for i,d in enumerate(docs)])\n",
    "  )\n",
    "\n",
    "docs = compression_pipeline.get_relevant_documents(\"What is hallucination keep your answer under 30 words?\")\n",
    "pretty_print_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TanmayRaju\\miniconda3\\envs\\genchatbot\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Negative prompting is a technique used to guide language models, such as the one you're interacting with, to avoid generating certain types of content. It provides specific directions to the model about aspects of the prompt that it should not include or generate during the generation process. This can help fine-tune the results generated by the model while keeping the prompt generic. Negative prompting can also be used to moderate the output content generated by the model, preventing harmful, offensive, or inappropriate content from being generated. It's a way to ensure that the model's responses are safe, accurate, and relevant to the prompt.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define an Advanced RAG\n",
    "from langchain.chains import RetrievalQA\n",
    "#\n",
    "qa_advanced = RetrievalQA.from_chain_type(llm=chat_llm,\n",
    "                                 chain_type=\"stuff\",\n",
    "                                 retriever=compression_pipeline,\n",
    "                                 return_source_documents=True)\n",
    "#\n",
    "qa_adv_response = qa_advanced(\"What is Negative prompting?\")  \n",
    "qa_adv_response[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is Negative prompting?',\n",
       " 'result': \"Negative prompting is a technique used to guide language models, such as the one you're interacting with, to avoid generating certain types of content. It provides specific directions to the model about aspects of the prompt that it should not include or generate during the generation process. This can help fine-tune the results generated by the model while keeping the prompt generic. Negative prompting can also be used to moderate the output content generated by the model, preventing harmful, offensive, or inappropriate content from being generated. It's a way to ensure that the model's responses are safe, accurate, and relevant to the prompt.\",\n",
       " 'source_documents': [_DocumentWithState(page_content='20\\nTABLE VI: Image generation examples\\nPrompt: Different famous personalities in roles other than their original ones\\nNegative Prompt: blurry, photorealistic\\nGenerated Images:\\na b c d\\nPrompt: Generate an image of Monalisa showing her teeth in a wedding ceremony\\nNegative Prompt: blurry, low resolution, artistic\\nGenerated Images:\\na b c d\\nPrompt: Area of rocks, deep inside the forest, divine domain, river, sunset, kids playing\\nNegative Prompt: artistic, blurry, background\\nGenerated Images:\\na b c d\\nPrompt: A man kissing a girl/ Generate an image of a guy/ woman\\nNegative Prompt: artistic, blurry, background, young\\nGenerated Images:\\na b c d', metadata={'source': 'data\\\\LLM_Final.pdf', 'page': 20, 'relevance_score': 0.69955295}, state={'embedded_doc': [0.05335327237844467, -0.02474883198738098, 0.03168898820877075, -0.03374110534787178, -0.027058687061071396, -0.00692744180560112, 0.00853931438177824, 0.02708885259926319, 0.015517967753112316, 0.00765537703409791, 0.047554124146699905, -0.08661630004644394, 0.07310324162244797, -0.006204719189554453, -0.05865161120891571, 0.004953016992658377, 0.03367261961102486, 0.013533410616219044, -0.024260755628347397, 0.007513728924095631, -0.01698094978928566, -0.05283549055457115, 0.0812806636095047, -0.06448699533939362, 0.007478192914277315, -0.008836697787046432, 0.004606159869581461, 0.01288076862692833, -0.0006353662465699017, -0.053682729601860046, -0.06906984746456146, 0.0908542200922966, 0.07654734700918198, 0.020099669694900513, -0.028799571096897125, 0.06678541749715805, -0.006290662568062544, 0.09302360564470291, 0.0270830150693655, -0.0017066325526684523, -0.0641140565276146, -0.03389682620763779, 0.007102819159626961, 0.02021370828151703, 0.03397055342793465, -0.04112279415130615, -0.05047178640961647, -0.04300863668322563, -0.060658544301986694, -0.00776228541508317, -0.1036759614944458, -0.042558323591947556, -0.08495128899812698, 0.07291382551193237, -0.009863032959401608, 0.0347205251455307, 0.001177513157017529, -0.061914701014757156, 0.032406214624643326, 0.04353555664420128, -0.0955662652850151, 0.010152701288461685, -0.02769671194255352, 0.037393759936094284, 0.07514867186546326, 0.047420259565114975, -0.005508382339030504, -0.0039393226616084576, 0.013634756207466125, 0.014588069170713425, -0.016641395166516304, -0.012711754068732262, -0.0038103933911770582, 0.01589343138039112, -0.050518304109573364, 0.04506269469857216, -0.039348870515823364, -0.09107638895511627, -0.028476273640990257, -0.12615090608596802, 0.061139341443777084, -0.014534788206219673, 0.002322834450751543, 0.03355035185813904, -0.04931851848959923, -0.00470466073602438, 0.030192038044333458, -0.07449369132518768, -0.09215067327022552, 0.011952328495681286, -0.11628712713718414, -0.08097678422927856, 0.04583330824971199, -0.0010737038683146238, -0.037383172661066055, 0.016273949295282364, 0.03575318306684494, -0.16364355385303497, 0.018797915428876877, 0.02249525487422943, -0.01227989699691534, -0.02010948583483696, 0.041701797395944595, 0.023349160328507423, -0.010420809499919415, -0.06197584792971611, 0.02874804474413395, -0.028979085385799408, -0.024356286972761154, -0.05024642497301102, -0.05198642611503601, 0.00760416965931654, -0.020446153357625008, -0.1173744723200798, 0.06598204374313354, -0.025463173165917397, 0.017081813886761665, 0.0006751752225682139, 0.05724213644862175, -0.06103415787220001, 0.0646136924624443, -0.005622777156531811, -0.0048126219771802425, -0.0023531224578619003, -0.027622725814580917, -0.09022315591573715, -0.07165338099002838, 3.710278573715635e-33, 0.040679436177015305, 0.001071895589120686, 0.10164797306060791, 0.11272943764925003, 0.0689086988568306, 0.04553043469786644, -0.014893321320414543, -0.027607247233390808, -0.002544338582083583, -0.02464466728270054, 0.019704585894942284, -0.0449230782687664, -0.08436409384012222, 0.14027349650859833, 0.01763094775378704, 0.039591141045093536, -0.01960403099656105, 0.03270614892244339, -0.06430269032716751, 0.043862178921699524, -0.02802208438515663, 0.12514075636863708, 0.012708567082881927, 0.018309885635972023, 0.046442270278930664, -0.029078803956508636, 0.02327948436141014, 0.0007051907596178353, 0.0473155602812767, 0.008424829691648483, -0.03810160607099533, 0.029895542189478874, 0.03484274446964264, -0.03415398299694061, 0.040561992675065994, 0.05641549453139305, -0.02635682187974453, -0.049314118921756744, 0.03917088732123375, 0.0707627683877945, -0.016802288591861725, 0.027899788692593575, -0.07543744146823883, 0.03666426241397858, 0.009391439147293568, 0.05269481986761093, 0.05949195846915245, 0.010095321573317051, -0.0729336068034172, 0.09868518263101578, 0.010770781897008419, 0.05458328127861023, -0.023342981934547424, -0.03288331255316734, 0.01495437417179346, -0.0004963664687238634, 0.012429678812623024, -0.06210378557443619, -0.04137152433395386, -0.018798140808939934, 0.10614201426506042, 0.05071739852428436, -0.028490012511610985, -0.019138474017381668, -0.007067085709422827, 0.014655295759439468, -0.009563331492245197, -0.05723986029624939, 0.04524683579802513, 0.01793685369193554, -0.07908810675144196, 0.04657047986984253, -0.03615394979715347, -0.08596969395875931, -0.026706576347351074, -0.002735935151576996, -0.0511510856449604, -0.04637359455227852, -0.02961081825196743, 0.025660833343863487, -0.06530909985303879, 0.0014642167370766401, -0.0751342624425888, -0.04175272211432457, -0.05329369008541107, -0.0381920300424099, 0.04035799577832222, -0.09231840819120407, -0.0629681795835495, -0.002875142265111208, 0.0384904183447361, 0.0471973642706871, 0.05493655800819397, 0.02102726139128208, -0.054933689534664154, -4.397388082549879e-33, -0.005932576954364777, 0.025595255196094513, -0.08860884606838226, 0.03068007342517376, 0.004182263743132353, 0.002496305387467146, 0.0627569779753685, 0.012712661176919937, 0.05062650889158249, -0.043146491050720215, -0.025864815339446068, 0.004616257734596729, -0.08564428240060806, -0.09870818257331848, -0.08296145498752594, -0.08267237991094589, 0.06314124166965485, 0.0015721659874543548, -0.06356838345527649, 0.07818911224603653, 0.03549879044294357, 0.11395175009965897, -0.050894271582365036, 0.00110513879917562, 0.013072692789137363, 0.07865621894598007, 0.03074958547949791, 0.051436830312013626, 0.00036036025267094374, 0.08013404905796051, 0.013712599873542786, 0.04144705832004547, 0.06623923033475876, 0.020333176478743553, -0.035492606461048126, 0.0033734417520463467, 0.04637075960636139, -0.08985260128974915, -0.017263449728488922, 0.039876412600278854, -0.00018563150661066175, 0.011329245753586292, 0.03935451805591583, 0.07247748970985413, -0.10918460786342621, -0.03814561292529106, -0.01364817377179861, 0.0162498876452446, 0.06520342826843262, 0.04937770217657089, -0.057035092264413834, -0.04122645780444145, -0.05088910833001137, -0.012073366902768612, -0.027328383177518845, -0.05588335543870926, -0.03016583062708378, 0.022012079134583473, 0.09509141743183136, 0.10249511897563934, -0.0012818626128137112, 0.03693649545311928, -0.0372873991727829, -0.1028955802321434, -0.06990872323513031, -0.028480391949415207, -0.05819658190011978, 0.03609176352620125, -0.027600646018981934, -0.018119625747203827, 0.04842456430196762, 0.0013318781275302172, -0.029533470049500465, -0.020725714042782784, 0.03290930390357971, -0.022530866786837578, -0.05266011878848076, -0.005598379764705896, -0.029506253078579903, -0.049638666212558746, -0.053634051233530045, -0.015141204930841923, -0.01798274926841259, 0.10411123186349869, -0.01149335503578186, 0.09170752763748169, -0.061885181814432144, -0.006292953621596098, 0.0001429538824595511, 0.10439714044332504, 0.02164219133555889, 0.010217149741947651, -0.00048460272955708206, 0.04106593132019043, 0.04413972422480583, -4.762508609701399e-08, -0.024392494931817055, -0.04596320912241936, 0.006584239657968283, -0.06431644409894943, 0.08744724839925766, -0.05547317862510681, -0.05319219455122948, 0.02301352471113205, 0.05823294445872307, -0.023421935737133026, -0.018878953531384468, 0.09371506422758102, -0.05536138266324997, -0.02095801942050457, 0.0866444781422615, 0.021908767521381378, 0.02768569439649582, 0.037786681205034256, -0.02106839418411255, -0.004515161272138357, 0.03740027919411659, 0.017714351415634155, -0.07736598700284958, -0.07096201181411743, -0.08380339294672012, 0.0483785979449749, -0.023974483832716942, -0.026585323736071587, -0.11087265610694885, 0.004933592397719622, 0.11314647644758224, 0.026038341224193573, 0.03365785628557205, -0.07356178015470505, 0.053241975605487823, 0.04521593078970909, -0.0731603354215622, -0.015467426739633083, -0.04970536381006241, -0.013165370561182499, 0.06093413382768631, -0.059513550251722336, 0.04229149967432022, 0.03704618290066719, -0.011438695713877678, 0.02599107287824154, 0.0638778954744339, -0.014985612593591213, 0.018947789445519447, 0.0014434204204007983, -0.04521515965461731, -0.03839479014277458, 0.03587642312049866, 0.013639534823596478, 0.021126188337802887, 0.052061572670936584, 0.12285245209932327, 0.11663619428873062, 0.03052598237991333, 0.05284574255347252, 0.12119908630847931, 0.043960489332675934, -0.004622704815119505, -0.00747018214315176]}),\n",
       "  _DocumentWithState(page_content='a positive sentiment and indicating its sentiment and doing\\nso with a negative tweet/tweets as well. Finally, the user can\\nthen use the LLM for tweet classification. Using in-context\\nlearning allows a user to “fine-tune” the LLM for the specific\\ntasks being performed in the application [204].\\n2) Negative Prompting: Negative prompting [205], [206],\\n[207] provides directions to the LLM about aspects of the\\nprompt that it should avoid generating or deliberately exclud-\\ning during the generation process [205]. Through the use of\\nnegative prompts, one can fine-tune the results generated by\\nthe LLM in response to a prompt while being able to keep the\\nprompt generation generic [208]. Another advantage of the\\nuse of negative prompting is that it allows for moderation of\\nthe output content generated by the model thereby preventing\\nharmful or inappropriate from being generated. \"Don’t write\\nanything that is offensive or harmful, or factually incorrect.\"\\nThis prompt tells the model to avoid generating text that could\\nbe offensive or harmful to others and inaccurate. Notably,\\nthe authors in [209] conducted experiments for text based\\nimage tranlation and found that negative prompting to be very', metadata={'source': 'data\\\\LLM_Final.pdf', 'page': 7, 'relevance_score': 0.07201431}, state={'embedded_doc': [-0.0029829370323568583, 0.04854726791381836, -0.006165368482470512, -0.022667545825242996, 0.08126510679721832, -0.024117683991789818, 0.10149376094341278, 0.06385137140750885, 0.051729846745729446, -0.033190492540597916, 0.04961967095732689, -0.02245510369539261, 0.14538201689720154, -0.02623126655817032, 0.025413652881979942, 0.023935427889227867, 0.1427423506975174, -0.03321247920393944, -0.04669296368956566, -0.01555612776428461, 0.024192268028855324, 0.019625918939709663, 0.08469186723232269, 0.004855910316109657, -0.08394469320774078, -0.05734524503350258, -0.02627578191459179, 0.015895361080765724, 0.06120818480849266, 0.01915821246802807, -0.07207212597131729, 0.06852182745933533, 0.01393796969205141, 0.03898143768310547, -0.10040993988513947, 0.04084474965929985, -0.04222426936030388, 0.06890782713890076, -0.052289433777332306, -0.03396826982498169, -0.061592649668455124, -0.07996534556150436, -0.0602995827794075, -0.0031669463496655226, -0.00141423218883574, -0.029566699638962746, -0.005305461119860411, -0.028473200276494026, -0.08889007568359375, -0.0008981644059531391, -0.042776331305503845, 0.013602479360997677, -0.0664018839597702, 0.012567611411213875, -0.08962541818618774, 0.020073065534234047, 0.04711242765188217, 0.0529036819934845, -0.03024383634328842, -0.00875586736947298, -0.04277871176600456, -0.066131092607975, -0.06515652686357498, 0.009333170019090176, 0.0690106600522995, -0.0034975188318639994, -0.02524818852543831, 0.05030496045947075, -0.008391361683607101, 0.03773581236600876, 0.045550815761089325, -0.03263592720031738, 0.05017489939928055, 0.03365118056535721, -0.07695642858743668, 0.04467949643731117, 0.05652027204632759, 0.030113738030195236, 0.0006959167658351362, -0.0267307348549366, 0.08285651355981827, 0.028434382751584053, 0.018062705174088478, -0.01044984720647335, 0.033999260514974594, -0.023845475167036057, -0.015642356127500534, 0.037473853677511215, 0.020216181874275208, 0.10424371063709259, 0.03248175233602524, -0.03986441716551781, 0.07273929566144943, -0.00914464145898819, 0.0016637789085507393, -0.009540984407067299, -0.05924885347485542, -0.10014832764863968, -0.03750522807240486, 0.037561144679784775, -0.021886514499783516, 0.012163055129349232, -0.02205900102853775, -0.018193339928984642, 0.028139878064393997, -0.02691911719739437, -0.03959576413035393, 0.014797079376876354, 0.06509184837341309, -0.05235674977302551, -0.0472697913646698, 0.0625835508108139, 0.0053154160268604755, -0.08068244159221649, 0.05252714827656746, -0.030143242329359055, 0.058507874608039856, 0.0020067067816853523, 0.07101086527109146, 0.010682218708097935, -0.02666528709232807, -0.04317271709442139, -0.05067658796906471, 0.011154956184327602, 0.050650790333747864, -0.06357622891664505, -0.07576143741607666, 4.202502874127052e-33, 0.0869143158197403, 0.07630821317434311, 0.024992551654577255, 0.07124011963605881, 0.027622919529676437, 0.06106949597597122, -0.04547886922955513, -0.021473169326782227, 0.006427634507417679, -0.019810007885098457, 0.02505037747323513, -0.01676454395055771, 0.030976537615060806, 0.09407060593366623, 0.050179701298475266, -0.02806284837424755, -0.03260958194732666, -0.03464191406965256, 0.007004826329648495, 0.015242239460349083, 0.009767618030309677, -0.023175520822405815, 0.02733026258647442, -0.043517906218767166, -0.029164103791117668, 0.03703484311699867, 0.05631320923566818, -0.024096312001347542, -0.014472565613687038, 0.03487532213330269, -0.11259637027978897, -0.005506666377186775, 0.0030718157067894936, -0.030068261548876762, 0.08631743490695953, -0.02005358599126339, -0.08640223741531372, 0.023791616782546043, -0.013266637921333313, -0.07141674309968948, 0.009085885249078274, 0.0693594440817833, 0.017352696508169174, 0.026571497321128845, -0.04950464144349098, 0.04559562727808952, 0.0610661543905735, -0.03577718511223793, -0.0605672188103199, 0.045562874525785446, 0.07984518259763718, 0.034224119037389755, -0.021540308371186256, -0.023108135908842087, 0.013363377191126347, 0.016828661784529686, 0.003966076299548149, -0.03696724399924278, 0.02037215232849121, -0.065668985247612, 0.00101347581949085, -0.00029957882361486554, 0.011972102336585522, -0.012306987307965755, 0.05334654822945595, -0.033709120005369186, -0.06180930510163307, -0.018775004893541336, -0.03861209377646446, -0.10140977054834366, -0.013207731768488884, -0.002602707827463746, -0.08411148190498352, -0.022814005613327026, -0.04762694239616394, -0.03087124414741993, 0.0036419492680579424, 0.00933943223208189, 0.09084360301494598, -0.03764311596751213, 0.08629389852285385, -0.043810367584228516, 0.0023605909664183855, -0.0776231661438942, -0.024200186133384705, -0.013145426288247108, 0.027534861117601395, -0.07316666841506958, -0.006353228818625212, 0.07885429263114929, -0.01217949390411377, 0.019345544278621674, -0.06194400414824486, 0.13964258134365082, -0.07489628344774246, -4.6219170544485365e-33, -0.0297866128385067, -0.0042478465475142, -0.12644492089748383, 0.03836273029446602, -0.04759366437792778, 0.004864342510700226, 0.05890550836920738, 0.027027787640690804, -0.014617368578910828, -0.049577001482248306, 0.010902824811637402, 0.012215646915137768, -0.07334226369857788, -0.050256893038749695, -0.04531201347708702, -0.11066480726003647, 0.004652883857488632, -0.0045331260189414024, -0.07577329874038696, -0.057079415768384933, -0.03539486601948738, 0.05213785916566849, -0.12889766693115234, 0.020424235612154007, -0.025249933823943138, 0.03827052563428879, -0.010131211020052433, 0.06039687991142273, -0.012429102323949337, 0.013003570958971977, 0.00968305766582489, 0.08238103985786438, 0.045241739600896835, 0.06515774130821228, -0.04202444478869438, 0.025787562131881714, 0.058524202555418015, 0.002905752509832382, 0.025729088112711906, 0.05090198293328285, 0.13766293227672577, 0.0684475302696228, 0.030940966680645943, 0.005015927366912365, -0.10116235166788101, -0.015779392793774605, -0.07659534364938736, -0.05927550047636032, 0.09347604215145111, 0.018768414855003357, 0.002776890993118286, -0.07419435679912567, -0.020691778510808945, 0.010285578668117523, -0.04416387528181076, -0.09221777319908142, -0.0009332941845059395, -0.07079444825649261, 0.01102945301681757, 0.0037359672132879496, -0.042546190321445465, -0.003711499273777008, 0.012670711614191532, -0.09218855202198029, -0.026907658204436302, -0.07352851331233978, -0.0019073509611189365, 0.0110769746825099, 0.0372144840657711, 0.010740591213107109, 0.05904557183384895, 0.054693881422281265, -0.04358762130141258, -0.07233162224292755, 0.035975027829408646, -0.061417270451784134, 0.024760272353887558, -0.003319168696179986, -0.0531194843351841, -0.10990491509437561, 0.001125145354308188, -0.0047259703278541565, -0.043000515550374985, 0.0981753021478653, -0.070013128221035, -0.010441385209560394, 0.03261508792638779, 0.07664550840854645, -0.016776932403445244, 0.021214798092842102, 0.04971146956086159, 0.08091630041599274, -0.022535918280482292, 0.10191475600004196, 0.07712594419717789, -6.006290220739174e-08, -0.05611259490251541, -0.08709771186113358, 0.008883749134838581, 0.08105763792991638, 0.040945008397102356, 0.028653783723711967, 0.009988425299525261, 0.012038367800414562, 0.07097794115543365, -0.04377070814371109, 0.02545332722365856, 0.02592116966843605, -0.12662334740161896, -0.06323976814746857, 0.005463049281388521, 0.05236814171075821, 0.0026721612084656954, -0.037923771888017654, -0.010406732559204102, -0.012197522446513176, 0.029753295704722404, -0.031757500022649765, -0.05832447111606598, 0.044383205473423004, 0.06844785064458847, -0.011802300810813904, -0.0011905529536306858, 0.04230441153049469, -0.03734089806675911, -0.038436610251665115, -0.01206920575350523, 0.02039039321243763, -0.08535078167915344, 0.031168527901172638, -0.03475672006607056, 0.08145763725042343, -0.061126917600631714, -0.07725845277309418, 0.05887072533369064, -0.028060831129550934, 0.016685882583260536, 0.07348115742206573, -0.03794395923614502, 0.006031045224517584, -0.057844437658786774, 0.03130759298801422, 0.03393973037600517, -0.1107344850897789, -0.07266762852668762, 0.05331088602542877, -0.0184786356985569, 0.011444181203842163, 0.029994750395417213, 0.09174377471208572, 0.011656696908175945, 0.004707077518105507, 0.0784073919057846, 0.0016596723580732942, 0.020011715590953827, 0.07815458625555038, 0.10484325140714645, 0.010976449586451054, -0.029907308518886566, -0.03217552229762077]}),\n",
       "  _DocumentWithState(page_content='models,” arXiv preprint arXiv:2305.16807 , 2023.\\n[206] N. Liu, S. Li, Y . Du, A. Torralba, and J. B. Tenenbaum, “Compositional\\nvisual generation with composable diffusion models,” in European\\nConference on Computer Vision , pp. 423–439, Springer, 2022.\\n[207] AUTOMATIC1111, “Negative-prompt.” https://github.com/AUTOM\\nATIC1111/stable-diffusion-webui/wiki/Negative-prompt, 2022.\\nAccessed on August 1, 2023.\\n[208] F. Ma, C. Zhang, L. Ren, J. Wang, Q. Wang, W. Wu, X. Quan, and\\nD. Song, “Xprompt: Exploring the extreme of prompt tuning,” arXiv\\npreprint arXiv:2210.04457 , 2022.\\n[209] N. Tumanyan, M. Geyer, S. Bagon, and T. Dekel, “Plug-and-play\\ndiffusion features for text-driven image-to-image translation,” in Pro-\\nceedings of the IEEE/CVF Conference on Computer Vision and Pattern\\nRecognition , pp. 1921–1930, 2023.\\n[210] H. Chang, H. Zhang, J. Barber, A. Maschinot, J. Lezama, L. Jiang,\\nM.-H. Yang, K. Murphy, W. T. Freeman, M. Rubinstein, et al. , “Muse:\\nText-to-image generation via masked generative transformers,” arXiv\\npreprint arXiv:2301.00704 , 2023.\\n[211] A. Chen, Y . Yao, P.-Y . Chen, Y . Zhang, and S. Liu, “Understanding\\nand improving visual prompting: A label-mapping perspective,” in', metadata={'page': 35, 'source': 'data\\\\LLM_Final.pdf', 'relevance_score': 0.047300927}, state={'embedded_doc': [-0.003646368160843849, -0.050052132457494736, 0.018871819600462914, 0.01848088763654232, 0.07432162016630173, -0.040417518466711044, -0.0001395836879964918, 0.03328028693795204, 0.07224124670028687, -0.056964971125125885, 0.041353821754455566, -0.048962365835905075, 0.054090458899736404, 0.04250611364841461, -0.005060891155153513, -0.034830547869205475, 0.11826949566602707, 0.002633262425661087, -0.048589516431093216, -0.034866079688072205, -0.05301078036427498, -0.05438924580812454, -0.0049748532474040985, -0.07293450832366943, -0.007428271695971489, 0.0582134947180748, -0.03373957425355911, -0.08663949370384216, 0.0645759329199791, -0.052085526287555695, -0.040187180042266846, 0.011554480530321598, 0.03423619642853737, 0.06923861801624298, -0.07160867750644684, 0.06415865570306778, -0.019060388207435608, 0.04536213353276253, -0.028132591396570206, -0.017573026940226555, -0.043607041239738464, 0.048715438693761826, 0.0056024822406470776, -0.023240646347403526, 0.12690530717372894, -0.05724542587995529, -0.059533052146434784, -0.006136422511190176, -0.028827888891100883, 0.016345588490366936, -0.1103445515036583, -0.004201163537800312, -0.04248368740081787, 0.03216325864195824, -0.054499637335538864, 0.09666471183300018, 0.13036035001277924, -0.024849949404597282, 0.014138164930045605, -0.003058725269511342, -0.07189127802848816, -0.02800748683512211, -0.053639862686395645, 0.007928311824798584, 0.09091898053884506, 0.02026085928082466, 0.07646287977695465, 0.006271501537412405, -0.03129717335104942, 0.10302341729402542, 0.007274373900145292, -0.02133827470242977, -0.034350231289863586, -0.053844042122364044, -0.006688566412776709, 0.08608238399028778, 0.03400764614343643, -0.014379527419805527, -0.011716358363628387, -0.10503717511892319, 0.1038648709654808, 0.012790662236511707, 0.038946639746427536, 0.0038910347502678633, 0.02181430533528328, -0.015504870563745499, -0.014951945282518864, 0.018715376034379005, 0.03077021986246109, 0.04960137978196144, -0.07947888970375061, -0.02295444719493389, -0.0731087327003479, 0.011004980653524399, 0.01246702391654253, 0.03109503537416458, 0.019721033051609993, -0.1283596009016037, 0.02127315290272236, 0.051819659769535065, 0.005979418288916349, -0.02877407893538475, 0.02621595747768879, -0.06676221638917923, 0.013068941421806812, -0.06158258020877838, 0.11350395530462265, 0.05387454852461815, 0.042111653834581375, -0.030194247141480446, 0.005121193360537291, -0.0035346411168575287, -0.011972467415034771, -0.03225209563970566, 0.02608654648065567, -0.07161775231361389, 0.06765357404947281, -0.014726266264915466, 0.08543357998132706, -0.0027498919516801834, 0.07084476202726364, -0.01913038268685341, -0.12672430276870728, 0.0027918023988604546, 0.0939042940735817, -0.057662416249513626, -0.013779250904917717, 1.4569296241338509e-34, -0.004158156458288431, -0.05667223781347275, 0.06550345569849014, 0.07636486738920212, 0.07769395411014557, 0.003455224446952343, -0.009809904731810093, -0.076975017786026, -0.0664474219083786, -0.07318668067455292, -0.044542960822582245, -0.016127772629261017, -0.09900786727666855, 0.1433633267879486, 0.036676421761512756, -0.107603058218956, 0.008233195170760155, 0.08226698637008667, -0.03628894314169884, -0.006113915238529444, 0.03679676726460457, -0.011208700947463512, -0.027386974543333054, -0.10394053906202316, 0.024702413007616997, 0.023888669908046722, -0.02175220288336277, -0.059456996619701385, -0.012102245353162289, 0.018238700926303864, -0.14263848960399628, 0.01815437152981758, 0.0007597891963087022, 0.0188312828540802, 0.00729022640734911, 0.015040106140077114, -0.10030126571655273, -0.026711100712418556, 0.0285889133810997, -0.02448909729719162, -0.027259761467576027, 0.08079801499843597, -0.016361849382519722, -0.012909606099128723, -0.058181364089250565, 0.022104086354374886, 0.006577636115252972, 0.05892272666096687, -0.10707549005746841, -0.04408868029713631, 0.03529972583055496, 0.012673910707235336, -0.0765019953250885, -0.0706799328327179, 0.05485999956727028, 0.012577206827700138, 0.07631915807723999, -0.017955292016267776, -0.00141524791251868, -0.037070803344249725, 0.07147262990474701, 0.061521753668785095, -0.04476950690150261, 0.023562876507639885, 0.05236630141735077, 0.03129027783870697, -0.07304492592811584, -0.028753099963068962, -0.035813361406326294, -0.008709150366485119, -0.06705477833747864, 0.03917759284377098, -0.06604593992233276, -0.07278481125831604, 0.05011657252907753, -0.034130264073610306, 0.02579553611576557, -0.02519771084189415, 0.09032698720693588, 0.019225362688302994, -0.0774657130241394, -0.07800164073705673, -0.054755233228206635, -0.06994807720184326, -0.01447441428899765, -0.0014751693233847618, 0.02811925858259201, -0.07812672108411789, -0.09888776391744614, -0.09728211909532547, 0.03628910705447197, 0.01807171106338501, 0.004610070027410984, 0.07068585604429245, 0.004609453957527876, -1.9337576347377584e-33, -0.04263736680150032, 0.026198962703347206, 0.006839608307927847, 0.11581350862979889, -0.07092279195785522, 0.01674133539199829, 0.067237488925457, 0.026645561680197716, 0.04708803817629814, -0.061050087213516235, -0.022046176716685295, 0.04125155508518219, -0.08908802270889282, 0.01400294341146946, -0.028863977640867233, -0.05865359306335449, 0.09136459231376648, 0.0032199916895478964, 0.01214491855353117, 0.017557144165039062, -0.003518664510920644, 0.045110367238521576, -0.057001564651727676, -0.017010273411870003, -0.02027941308915615, 0.03251044079661369, 0.0008179470896720886, 0.08363156020641327, -0.0342915877699852, -0.04085486754775047, -0.054865818470716476, 0.07859882712364197, -0.007417063228785992, 0.012283649295568466, -0.020266732200980186, 0.06773066520690918, -0.0031010769307613373, 0.024624526500701904, -0.03215612843632698, 0.07331345975399017, 0.05690149962902069, -0.006121066398918629, -0.038062579929828644, 0.05927294120192528, -0.015290167182683945, 0.0064523592591285706, -0.032257694751024246, 0.02465461753308773, 0.04836928844451904, 0.04672214761376381, -0.017239674925804138, 0.03613734617829323, -0.03666448965668678, 0.024213751778006554, -0.05773389711976051, -0.014564280398190022, -0.06179284676909447, -0.039779454469680786, 0.06853849440813065, -0.017040938138961792, -0.08410634100437164, -0.015362854115664959, 0.03552117943763733, -0.11675899475812912, -0.029711196199059486, -0.02038535289466381, -0.04977956414222717, 0.006747815757989883, 0.048908621072769165, 0.04647308588027954, 0.04058032110333443, 0.027288328856229782, -0.030813461169600487, 0.00035242311423644423, 0.03920541703701019, -0.04914242774248123, 0.046108994632959366, -0.011858511716127396, -9.092254913412035e-05, -0.07264205068349838, 0.015898754820227623, 0.07365506142377853, -0.007084439042955637, 0.08480434864759445, -0.007543022744357586, 0.04551103711128235, -0.059222206473350525, 0.017046526074409485, 0.030227376148104668, 0.07076713442802429, -0.005104884505271912, -0.0003200061328243464, 0.04299822449684143, 0.09316924214363098, -0.025397861376404762, -5.855022422451839e-08, -0.08072903752326965, 0.03974350914359093, 0.04349576309323311, 0.018771467730402946, 0.06011989712715149, -0.046618182212114334, 0.053849492222070694, -0.03537055850028992, 0.01681278832256794, -0.028598466888070107, 0.02057565189898014, 0.028333084657788277, -0.019497331231832504, -0.034505002200603485, -0.02519560605287552, 0.11867544054985046, 0.01977689191699028, -0.01204974390566349, -0.023312067613005638, -0.01652512513101101, -0.009584466926753521, 0.02427670545876026, -0.01876159943640232, 0.028776945546269417, 0.0018720703665167093, 0.009407158941030502, -0.0404183603823185, -0.009931232780218124, 0.02656496874988079, -0.0736517533659935, 0.05214723199605942, 0.04742569103837013, -0.048332881182432175, 0.0651695728302002, 0.03291752561926842, 0.03758572041988373, 0.003274348797276616, -0.0162973552942276, -0.04587595537304878, -0.06884334981441498, 0.010675221681594849, 0.059340376406908035, -0.038636885583400726, -0.026663001626729965, 0.003380346577614546, 0.033867478370666504, 0.05660007521510124, -0.09467271715402603, -0.016133839264512062, 0.02631469815969467, -0.0015047795604914427, -0.054571326822042465, -0.05041750147938728, 0.06838171184062958, 0.04350452125072479, 0.009964676573872566, 0.07857294380664825, -0.024055391550064087, 0.04376402497291565, 0.11838269233703613, 0.027868742123246193, 0.05850060284137726, 0.022724345326423645, 0.00840394664555788]})]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_adv_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was the revenue decline in mainland China...</td>\n",
       "      <td>['------- \\n \\n          Thank you, Tim, and g...</td>\n",
       "      <td>The revenue decline in mainland China for the ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'C:\\\\Users\\\\TanmayRaju\\\\Documents\\...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What was the value of Apple's channel inventor...</td>\n",
       "      <td>[\"market now reaching a pretty mature growth b...</td>\n",
       "      <td>The value of Apple's channel inventory reducti...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'C:\\\\Users\\\\TanmayRaju\\\\Documents\\...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the significance of Apple's 1 billion ...</td>\n",
       "      <td>[\"The services business is powered by our huge...</td>\n",
       "      <td>Apple's 1 billion active devices are a signifi...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'C:\\\\Users\\\\TanmayRaju\\\\Documents\\...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the significance of the 10 million con...</td>\n",
       "      <td>[\"The services business is powered by our huge...</td>\n",
       "      <td>The 10 million contactless ready locations in ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'C:\\\\Users\\\\TanmayRaju\\\\Documents\\...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What was the date of Apple Inc's Q1 2018 earni...</td>\n",
       "      <td>['Thomson Reuters StreetEvents Event Brief \\nE...</td>\n",
       "      <td>The date of Apple Inc's Q1 2018 earnings call ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'C:\\\\Users\\\\TanmayRaju\\\\Documents\\...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the purpose of the Thomson Reuters Str...</td>\n",
       "      <td>['Thomson Reuters StreetEvents Event Brief \\nE...</td>\n",
       "      <td>The Thomson Reuters StreetEvents Event Brief p...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'C:\\\\Users\\\\TanmayRaju\\\\Documents\\...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How has the upgrade rate for Apple devices cha...</td>\n",
       "      <td>['you\\'ve talked about 15% for Q2. &lt;Sync id=\"L...</td>\n",
       "      <td>The context does not provide specific informat...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'C:\\\\Users\\\\TanmayRaju\\\\Documents\\...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How has the upgrade rate for Apple devices cha...</td>\n",
       "      <td>['you\\'ve talked about 15% for Q2. &lt;Sync id=\"L...</td>\n",
       "      <td>The context does not provide specific informat...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'C:\\\\Users\\\\TanmayRaju\\\\Documents\\...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How has Apple's focus on creating a great cust...</td>\n",
       "      <td>['driving earnings. How do you think about it?...</td>\n",
       "      <td>Apple's focus on creating a great customer exp...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'C:\\\\Users\\\\TanmayRaju\\\\Documents\\...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1. How might the drive for improvement in larg...</td>\n",
       "      <td>['25\\nFig. 10: Demonstration of code generatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'data\\\\LLM_Final.pdf', 'page': 25}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What was the revenue decline in mainland China...   \n",
       "1  What was the value of Apple's channel inventor...   \n",
       "2  What is the significance of Apple's 1 billion ...   \n",
       "3  What is the significance of the 10 million con...   \n",
       "4  What was the date of Apple Inc's Q1 2018 earni...   \n",
       "5  What is the purpose of the Thomson Reuters Str...   \n",
       "6  How has the upgrade rate for Apple devices cha...   \n",
       "7  How has the upgrade rate for Apple devices cha...   \n",
       "8  How has Apple's focus on creating a great cust...   \n",
       "9  1. How might the drive for improvement in larg...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  ['------- \\n \\n          Thank you, Tim, and g...   \n",
       "1  [\"market now reaching a pretty mature growth b...   \n",
       "2  [\"The services business is powered by our huge...   \n",
       "3  [\"The services business is powered by our huge...   \n",
       "4  ['Thomson Reuters StreetEvents Event Brief \\nE...   \n",
       "5  ['Thomson Reuters StreetEvents Event Brief \\nE...   \n",
       "6  ['you\\'ve talked about 15% for Q2. <Sync id=\"L...   \n",
       "7  ['you\\'ve talked about 15% for Q2. <Sync id=\"L...   \n",
       "8  ['driving earnings. How do you think about it?...   \n",
       "9  ['25\\nFig. 10: Demonstration of code generatio...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  The revenue decline in mainland China for the ...         simple   \n",
       "1  The value of Apple's channel inventory reducti...         simple   \n",
       "2  Apple's 1 billion active devices are a signifi...         simple   \n",
       "3  The 10 million contactless ready locations in ...         simple   \n",
       "4  The date of Apple Inc's Q1 2018 earnings call ...         simple   \n",
       "5  The Thomson Reuters StreetEvents Event Brief p...         simple   \n",
       "6  The context does not provide specific informat...         simple   \n",
       "7  The context does not provide specific informat...         simple   \n",
       "8  Apple's focus on creating a great customer exp...         simple   \n",
       "9                                                NaN  multi_context   \n",
       "\n",
       "                                            metadata  episode_done  \n",
       "0  [{'source': 'C:\\\\Users\\\\TanmayRaju\\\\Documents\\...          True  \n",
       "1  [{'source': 'C:\\\\Users\\\\TanmayRaju\\\\Documents\\...          True  \n",
       "2  [{'source': 'C:\\\\Users\\\\TanmayRaju\\\\Documents\\...          True  \n",
       "3  [{'source': 'C:\\\\Users\\\\TanmayRaju\\\\Documents\\...          True  \n",
       "4  [{'source': 'C:\\\\Users\\\\TanmayRaju\\\\Documents\\...          True  \n",
       "5  [{'source': 'C:\\\\Users\\\\TanmayRaju\\\\Documents\\...          True  \n",
       "6  [{'source': 'C:\\\\Users\\\\TanmayRaju\\\\Documents\\...          True  \n",
       "7  [{'source': 'C:\\\\Users\\\\TanmayRaju\\\\Documents\\...          True  \n",
       "8  [{'source': 'C:\\\\Users\\\\TanmayRaju\\\\Documents\\...          True  \n",
       "9    [{'source': 'data\\\\LLM_Final.pdf', 'page': 25}]          True  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaldf = pd.read_csv(r\"C:\\Users\\TanmayRaju\\Documents\\GitHub\\AdvRAG\\new\\data\\combined_testset.csv\")\n",
    "evaldf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TanmayRaju\\miniconda3\\envs\\genchatbot\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Filename and doc_id are the same for all nodes.                   \n",
      "Generating: 100%|██████████| 10/10 [00:46<00:00,  4.67s/it]\n"
     ]
    }
   ],
   "source": [
    "# Synthetic Test Set Generation\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "#\n",
    "#load documents again to avoid any kind of bias\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 200\n",
    ")\n",
    "documents = text_splitter.split_documents(documents)\n",
    "#\n",
    "generator_llm = ChatDatabricks(endpoint=\"databricks-dbrx-instruct\", max_tokens = 200)\n",
    "critic_llm = ChatDatabricks(endpoint=\"databricks-dbrx-instruct\", max_tokens = 200)\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "#\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    embeddings\n",
    ")\n",
    "#\n",
    "testset = generator.generate_with_langchain_docs(documents, test_size=10, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the difference between artificial gene...</td>\n",
       "      <td>[30\\n•Source of Inspiration, Suggestions: LLMs...</td>\n",
       "      <td>Artificial general intelligence (AGI) refers t...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data\\LLM_Final.pdf', 'page': 30}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the first step in using large language...</td>\n",
       "      <td>[human language.\\nLastly, third-party plugins ...</td>\n",
       "      <td>The first step in using large language models ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data\\LLM_Final.pdf', 'page': 23}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can a question answering system be general...</td>\n",
       "      <td>[tasks via text generation,” in International ...</td>\n",
       "      <td>A question answering system can be generalized...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data\\LLM_Final.pdf', 'page': 36}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the use case for the Language Translat...</td>\n",
       "      <td>[24\\nTABLE IX: Some ChatGPT Plugins. This list...</td>\n",
       "      <td>The Language Translation plugin in ChatGPT can...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data\\LLM_Final.pdf', 'page': 24}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How has ChatGPT been applied in the fields of ...</td>\n",
       "      <td>[vol. 237, no. 8, pp. 1855–1876, 2023.\\n[367] ...</td>\n",
       "      <td>According to the provided context, ChatGPT has...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data\\LLM_Final.pdf', 'page': 38}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the difference between artificial gene...   \n",
       "1  What is the first step in using large language...   \n",
       "2  How can a question answering system be general...   \n",
       "3  What is the use case for the Language Translat...   \n",
       "4  How has ChatGPT been applied in the fields of ...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [30\\n•Source of Inspiration, Suggestions: LLMs...   \n",
       "1  [human language.\\nLastly, third-party plugins ...   \n",
       "2  [tasks via text generation,” in International ...   \n",
       "3  [24\\nTABLE IX: Some ChatGPT Plugins. This list...   \n",
       "4  [vol. 237, no. 8, pp. 1855–1876, 2023.\\n[367] ...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  Artificial general intelligence (AGI) refers t...         simple   \n",
       "1  The first step in using large language models ...         simple   \n",
       "2  A question answering system can be generalized...         simple   \n",
       "3  The Language Translation plugin in ChatGPT can...         simple   \n",
       "4  According to the provided context, ChatGPT has...         simple   \n",
       "\n",
       "                                         metadata  episode_done  \n",
       "0  [{'source': 'data\\LLM_Final.pdf', 'page': 30}]          True  \n",
       "1  [{'source': 'data\\LLM_Final.pdf', 'page': 23}]          True  \n",
       "2  [{'source': 'data\\LLM_Final.pdf', 'page': 36}]          True  \n",
       "3  [{'source': 'data\\LLM_Final.pdf', 'page': 24}]          True  \n",
       "4  [{'source': 'data\\LLM_Final.pdf', 'page': 38}]          True  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = testset.to_pandas()\n",
    "test_questions = test_df[\"question\"].values.tolist()\n",
    "test_groundtruths = test_df[\"ground_truth\"].values.tolist()\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the difference between artificial general intelligence (AGI) and the current capabilities of language models like me?',\n",
       " 'answer': 'The current capabilities of language models like you are impressive, but they are still far from the hypothetical concept of Artificial General Intelligence (AGI). AGI refers to a type of artificial intelligence that has the ability to learn and perform any intellectual task, much like a human. This means that an AGI system would be able to understand, learn, and apply knowledge across a wide range of tasks and domains, and adapt to new situations and environments.\\n\\nWhile language models like you have made significant contributions to various domains and can perform a variety of tasks, such as solving math problems, writing creative content, and answering questions in an informative way, they still have significant limitations and challenges. For example, you may rely too heavily on surface-level patterns, have limited common sense and reasoning abilities, and struggle with understanding syntax and grammar. Additionally, you may have difficulty with rare or out-of-vocabulary words, limited generalizability, and limited domain-specific knowledge.\\n\\nFurthermore, AGI is expected to have a deep',\n",
       " 'contexts': ['30\\n•Source of Inspiration, Suggestions: LLMs can serve as\\nan invaluable source of inspiration and suggestions, help-\\ning users brainstorm ideas [602], create content [603], and\\nmake decisions [604].\\n•Copilots Over Autonomous Agents: Given its limita-\\ntions, LLMs are better suited as a ’copilot’ that provides\\nassistance and suggestions, rather than an autonomous\\nagent that acts without human input or oversight [605],\\n[606].\\n•Artificial General Intelligence - AGI Artificial general\\nintelligence (AGI [607]) is a hypothetical type of artificial\\nintelligence that would have the ability to learn and\\nperform any intellectual task. In [312], GPT-4 is found\\nto have sparks of artificial general intelligence. GPT-4 is\\nable to perform a variety of tasks; such as solving math\\nproblems, writing creative contents, writing poems and\\npoetry [608] and answering questions in an informative\\nway.\\nHowever, in our opinion, realizing the dream of AGI is\\nstill far away, despite of the rapid progress in the LLMs\\ndevelopment. The key challenges include; understanding\\nnatural intelligence [609], developing adaptable fully au-\\ntonomous models [610], and being safe and reliable with\\nthe understanding of the physical world [611], [612].',\n",
       "  'Acronym Definition\\nAI Artificial Intelligence\\nAGI Artificial General Intelligence\\nBBH Big Bench Hard\\nBERT Bidirectional Encoder Representations from Transformers\\nCV Computer Vision\\nChatGPT A Large Language Model by OpenAI\\nCTRL Conditional Transformer Language Model\\nFFF Fused Filament Fabrication\\nGANs Generative Adversarial Networks\\nGNMT Google Neural Machine Translation\\nGPT Generative Pre-Trained transformers\\nGenAI Generative AI\\nGPT-3 Generative Pre-trained Transformer 3\\nGPT-4 Generative Pre-trained Transformer 4\\nGPUs Graphical Processing Units\\nGRUs Gated Recurrent Units\\nLLaMA Large Language Model Meta AI\\nLLM Large Language Models\\nLM Language Model\\nLSTM Long Short-Term Memory\\nML Machine Learning\\nMLM Masked Language Modeling\\nNSP Next Sentence Prediction\\nNLP Natural Language Processing\\nNLTK Natural Language Toolkit\\nPLMs Pre-trained Language Models\\nRLHF Reinforcement Learning Human Feedback\\nRNN Recurrent neural networks\\nRNNLM Recurrent neural network language model\\nSLMs Statistical Language Models\\nT2V Text to video\\nT5 Text-to-Text Transfer Transformer\\nTPUs Tensor Processing Units\\nUSMLE United States Medical Licensing Exam\\nVL-PTMs Vision-Language Pre-trained Models\\nXLNet eXtreme Language Understanding Network\\nand advancements.',\n",
       "  '26\\nIX. C HALLENGES AND LIMITATIONS OF LARGE\\nLANGUAGE MODELS\\nAlthough LLMs have made significant contributions to\\nvarious domains, they have significant limitations and chal-\\nlenges [105], [114]. LLMs are currently perceived as forerun-\\nners of Artificial General Intelligence (AGI). However, despite\\ntheir phenomenal success in conversational tasks, the state-of-\\nthe-art LLMs still lack in many aspects that makes them less\\nlikely an early manifestation of AGI. We first provide a quick\\nlist of the challenges and limitations of LLMs (Fig. 14) and\\nthen present a more detailed discussion on a few limitations\\nof critical concerns.\\nA number of challenges and limitations have been fo-\\ncused on, including biased data, overreliance on surface-level\\npatterns, limited common sense, poor ability to reason and\\ninterpret feedback [506], [507]. Other issues include; the need\\nfor vast amounts of data and computational resources [508],\\nlimited generalizability [509], lack of interpretability [510],\\ndifficulty with rare or out-of-vocabulary words, limited under-\\nstanding of syntax and grammar [511], and limited domain-\\nspecific knowledge [512].\\nThe susceptibility to adversarial attacks [242], ethical con-'],\n",
       " 'ground_truth': \"Artificial general intelligence (AGI) refers to a hypothetical type of artificial intelligence that can learn and perform any intellectual task, much like a human. In contrast, current language models like me have specific capabilities, such as generating text based on the input given, but they do not possess the ability to learn and perform any intellectual task autonomously. Instead, they serve as a 'copilot' that provides assistance and suggestions, helping users with a variety of tasks such as brainstorming ideas, creating content, and answering questions.\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Generate responses using our Advanced RAG pipeline using the questions we’ve generated.\n",
    "adv_answers = []\n",
    "adv_contexts = []\n",
    "\n",
    "for question in test_questions:\n",
    "  response = qa_advanced.invoke({\"query\" : question})\n",
    "  adv_answers.append(response[\"result\"])\n",
    "  adv_contexts.append([context.page_content for context in response['source_documents']])\n",
    "\n",
    "#wrap into huggingface dataset\n",
    "response_dataset_advanced_retrieval = Dataset.from_dict({\n",
    "    \"question\" : test_questions,\n",
    "    \"answer\" : adv_answers,\n",
    "    \"contexts\" : adv_contexts,\n",
    "    \"ground_truth\" : test_groundtruths\n",
    "})\n",
    "response_dataset_advanced_retrieval[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase2data =response_dataset_advanced_retrieval.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "customphase2data =phase2data[[\"question\", \"answer\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 334.61ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5732"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customphase2data = Dataset.from_dict({\n",
    "    \"question\" : test_questions,\n",
    "    \"ground_truth\" : test_groundtruths\n",
    "})\n",
    "\n",
    "customphase2data.to_csv(r'C:\\Users\\TanmayRaju\\Documents\\GitHub\\AdvRAG\\new\\data\\customphase2data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The metric [answer_relevancy] that that is used requires the following additional columns ['contexts', 'answer'] to be present in the dataset. ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 18\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     answer_relevancy,\n\u001b[0;32m      4\u001b[0m     faithfulness,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     answer_correctness\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m metrics \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# faithfulness,\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     answer_relevancy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     answer_correctness,\n\u001b[0;32m     16\u001b[0m ]\n\u001b[1;32m---> 18\u001b[0m advanced_retrieval_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustomphase2data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchat_llm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m advanced_retrieval_results\n",
      "File \u001b[1;32mc:\\Users\\TanmayRaju\\miniconda3\\envs\\genchatbot\\lib\\site-packages\\ragas\\evaluation.py:156\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(dataset, metrics, llm, embeddings, callbacks, in_ci, is_async, run_config, raise_exceptions, column_map)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# validation\u001b[39;00m\n\u001b[0;32m    155\u001b[0m dataset \u001b[38;5;241m=\u001b[39m handle_deprecated_ground_truths(dataset)\n\u001b[1;32m--> 156\u001b[0m \u001b[43mvalidate_evaluation_modes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m validate_column_dtypes(dataset)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# set the llm and embeddings\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\TanmayRaju\\miniconda3\\envs\\genchatbot\\lib\\site-packages\\ragas\\validation.py:96\u001b[0m, in \u001b[0;36mvalidate_evaluation_modes\u001b[1;34m(ds, metrics, evalmode_to_columns)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(m, ContextPrecision)\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mground_truth\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m available_columns\n\u001b[0;32m     93\u001b[0m ):\n\u001b[0;32m     94\u001b[0m     extra_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLooks like you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre trying to use \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext_precision\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m without ground_truth. Please use consider using  `context_utilization\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe metric [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] that that is used requires the following \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madditional columns \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(required_columns\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mavailable_columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto be present in the dataset. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextra_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: The metric [answer_relevancy] that that is used requires the following additional columns ['contexts', 'answer'] to be present in the dataset. "
     ]
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_correctness\n",
    ")\n",
    "\n",
    "metrics = [\n",
    "    # faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_correctness,\n",
    "]\n",
    "\n",
    "advanced_retrieval_results = evaluate(customphase2data, metrics, llm=chat_llm, embeddings=embeddings, raise_exceptions=False)\n",
    "advanced_retrieval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  18%|█▊        | 9/50 [00:13<00:53,  1.29s/it]Failed to parse output. Returning None.\n",
      "Evaluating:  22%|██▏       | 11/50 [00:15<00:39,  1.01s/it]Failed to parse output. Returning None.\n",
      "Failed to parse output. Returning None.\n",
      "Evaluating:  24%|██▍       | 12/50 [00:16<00:42,  1.11s/it]Failed to parse output. Returning None.\n",
      "Evaluating:  26%|██▌       | 13/50 [00:16<00:30,  1.20it/s]Failed to parse output. Returning None.\n",
      "Evaluating:  32%|███▏      | 16/50 [00:18<00:19,  1.72it/s]Failed to parse output. Returning None.\n",
      "Evaluating:  34%|███▍      | 17/50 [00:18<00:19,  1.69it/s]Failed to parse output. Returning None.\n",
      "Evaluating:  40%|████      | 20/50 [00:20<00:16,  1.77it/s]Failed to parse output. Returning None.\n",
      "Evaluating:  50%|█████     | 25/50 [00:24<00:27,  1.09s/it]Failed to parse output. Returning None.\n",
      "Evaluating:  62%|██████▏   | 31/50 [00:28<00:15,  1.26it/s]Failed to parse output. Returning None.\n",
      "Evaluating:  64%|██████▍   | 32/50 [00:29<00:11,  1.59it/s]Failed to parse output. Returning None.\n",
      "Failed to parse output. Returning None.\n",
      "Evaluating:  68%|██████▊   | 34/50 [00:29<00:09,  1.77it/s]Failed to parse output. Returning None.\n",
      "Evaluating:  70%|███████   | 35/50 [00:30<00:07,  2.05it/s]Failed to parse output. Returning None.\n",
      "Evaluating:  84%|████████▍ | 42/50 [00:36<00:06,  1.20it/s]Failed to parse output. Returning None.\n",
      "Evaluating:  88%|████████▊ | 44/50 [00:37<00:04,  1.41it/s]Failed to parse output. Returning None.\n",
      "Failed to parse output. Returning None.\n",
      "Evaluating:  92%|█████████▏| 46/50 [00:40<00:04,  1.16s/it]Failed to parse output. Returning None.\n",
      "Evaluating:  94%|█████████▍| 47/50 [00:41<00:02,  1.02it/s]Failed to parse output. Returning None.\n",
      "Failed to parse output. Returning None.\n",
      "Evaluating: 100%|██████████| 50/50 [00:44<00:00,  1.13it/s]\n",
      "c:\\Users\\TanmayRaju\\miniconda3\\envs\\genchatbot\\lib\\site-packages\\ragas\\evaluation.py:299: RuntimeWarning: Mean of empty slice\n",
      "  value = np.nanmean(self.scores[cn])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'faithfulness': nan, 'answer_relevancy': 0.7251, 'context_recall': 0.9259, 'context_precision': 0.9833, 'answer_correctness': 0.7202}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_correctness\n",
    ")\n",
    "\n",
    "metrics = [\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_correctness,\n",
    "]\n",
    "\n",
    "advanced_retrieval_results = evaluate(response_dataset_advanced_retrieval, metrics, llm=chat_llm, embeddings=embeddings, raise_exceptions=False)\n",
    "advanced_retrieval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing our evalframework function\n",
    "\n",
    "def eval_framework(filepath, customchain, myllm, testsize ):\n",
    "\n",
    "    # Load your doc\n",
    "    loader = PyPDFLoader(filepath)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Document Splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 1000,\n",
    "        chunk_overlap = 200\n",
    "    )\n",
    "    documents = text_splitter.split_documents(documents)\n",
    "    #\n",
    "    generator_llm = myllm\n",
    "    critic_llm = myllm\n",
    "    embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "    #\n",
    "    generator = TestsetGenerator.from_langchain(\n",
    "        generator_llm,\n",
    "        critic_llm,\n",
    "        embeddings\n",
    "    )\n",
    "    #\n",
    "    testset = generator.generate_with_langchain_docs(documents, test_size=testsize, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})\n",
    "\n",
    "    test_df = testset.to_pandas()\n",
    "    test_questions = test_df[\"question\"].values.tolist()\n",
    "    test_groundtruths = test_df[\"ground_truth\"].values.tolist()\n",
    "\n",
    "    # Generate responses using our Advanced RAG pipeline using the questions we’ve generated.\n",
    "    adv_answers = []\n",
    "    adv_contexts = []\n",
    "\n",
    "    for question in test_questions:\n",
    "        response = customchain.invoke({\"query\" : question})\n",
    "        adv_answers.append(response[\"result\"])\n",
    "        adv_contexts.append([context.page_content for context in response['source_documents']])\n",
    "\n",
    "    #wrap into huggingface dataset\n",
    "    response_dataset_advanced_retrieval = Dataset.from_dict({\n",
    "        \"question\" : test_questions,\n",
    "        \"answer\" : adv_answers,\n",
    "        \"contexts\" : adv_contexts,\n",
    "        \"ground_truth\" : test_groundtruths\n",
    "    })\n",
    "\n",
    "    metrics = [\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "        context_precision,\n",
    "        answer_correctness,\n",
    "    ]\n",
    "\n",
    "    advanced_retrieval_results = evaluate(response_dataset_advanced_retrieval, metrics, llm=myllm, embeddings=embeddings, raise_exceptions=False)\n",
    "    \n",
    "    return advanced_retrieval_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TanmayRaju\\miniconda3\\envs\\genchatbot\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Filename and doc_id are the same for all nodes.                   \n",
      "Generating: 100%|██████████| 2/2 [00:06<00:00,  3.42s/it]\n",
      "Evaluating:  60%|██████    | 6/10 [00:06<00:03,  1.07it/s]Failed to parse output. Returning None.\n",
      "Failed to parse output. Returning None.\n",
      "Evaluating:  70%|███████   | 7/10 [00:11<00:05,  1.97s/it]Failed to parse output. Returning None.\n",
      "Evaluating:  90%|█████████ | 9/10 [00:14<00:01,  1.79s/it]Failed to parse output. Returning None.\n",
      "Evaluating: 100%|██████████| 10/10 [00:15<00:00,  1.52s/it]\n",
      "c:\\Users\\TanmayRaju\\miniconda3\\envs\\genchatbot\\lib\\site-packages\\ragas\\evaluation.py:299: RuntimeWarning: Mean of empty slice\n",
      "  value = np.nanmean(self.scores[cn])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': nan, 'answer_relevancy': 0.9069, 'context_recall': 0.8333, 'context_precision': 0.9167, 'answer_correctness': 0.2283}\n"
     ]
    }
   ],
   "source": [
    "# testing evalframework\n",
    "scoreoutput = eval_framework(filepath=\"C:/Users/TanmayRaju/Documents/GitHub/AdvRAG/new/data/LLM_Final.pdf\", customchain=qa_advanced, myllm=chat_llm, testsize=2)\n",
    "print(scoreoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing our V2 evalframework function\n",
    "\n",
    "def eval_frameworkv2(filepath, groundtruthdataset, customchain, myllm):\n",
    "\n",
    "    # Load your doc\n",
    "    loader = PyPDFLoader(filepath)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Document Splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 1000,\n",
    "        chunk_overlap = 200\n",
    "    )\n",
    "    documents = text_splitter.split_documents(documents)\n",
    "    #\n",
    "    embeddings = HuggingFaceEmbeddings()\n",
    "    #\n",
    "    usertestdf = pd.read_csv(groundtruthdataset)\n",
    "    test_questions = usertestdf[\"question\"].values.tolist()\n",
    "    test_groundtruths = usertestdf[\"ground_truth\"].values.tolist()\n",
    "\n",
    "    # Generate responses using our Advanced RAG pipeline using the questions we’ve generated.\n",
    "    adv_answers = []\n",
    "    adv_contexts = []\n",
    "\n",
    "    for question in test_questions:\n",
    "        response = customchain.invoke({\"query\" : question})\n",
    "        adv_answers.append(response[\"result\"])\n",
    "        adv_contexts.append([context.page_content for context in response['source_documents']])\n",
    "\n",
    "    #wrap into huggingface dataset\n",
    "    response_dataset_advanced_retrieval = Dataset.from_dict({\n",
    "        \"question\" : test_questions,\n",
    "        \"answer\" : adv_answers,\n",
    "        \"contexts\" : adv_contexts,\n",
    "        \"ground_truth\" : test_groundtruths\n",
    "    })\n",
    "\n",
    "    metrics = [\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "        context_precision,\n",
    "        answer_correctness,\n",
    "    ]\n",
    "\n",
    "    advanced_retrieval_results = evaluate(response_dataset_advanced_retrieval, metrics, llm=myllm, embeddings=embeddings, raise_exceptions=False)\n",
    "    \n",
    "    return advanced_retrieval_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TanmayRaju\\miniconda3\\envs\\genchatbot\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Evaluating:  30%|███       | 15/50 [00:16<00:39,  1.14s/it]Failed to parse output. Returning None.\n",
      "Evaluating:  32%|███▏      | 16/50 [00:18<00:49,  1.45s/it]Failed to parse output. Returning None.\n",
      "Evaluating:  34%|███▍      | 17/50 [00:20<00:47,  1.43s/it]Failed to parse output. Returning None.\n",
      "Evaluating:  36%|███▌      | 18/50 [00:21<00:41,  1.29s/it]Failed to parse output. Returning None.\n",
      "Evaluating:  44%|████▍     | 22/50 [00:22<00:18,  1.55it/s]Failed to parse output. Returning None.\n",
      "Evaluating:  46%|████▌     | 23/50 [00:23<00:18,  1.44it/s]Failed to parse output. Returning None.\n",
      "Evaluating:  48%|████▊     | 24/50 [00:24<00:22,  1.14it/s]Failed to parse output. Returning None.\n",
      "Evaluating:  58%|█████▊    | 29/50 [00:28<00:16,  1.27it/s]Failed to parse output. Returning None.\n",
      "Evaluating:  64%|██████▍   | 32/50 [00:30<00:15,  1.15it/s]Failed to parse output. Returning None.\n",
      "Evaluating:  68%|██████▊   | 34/50 [00:31<00:11,  1.36it/s]Failed to parse output. Returning None.\n",
      "Evaluating:  78%|███████▊  | 39/50 [00:35<00:06,  1.68it/s]Failed to parse output. Returning None.\n",
      "Evaluating:  80%|████████  | 40/50 [00:37<00:09,  1.06it/s]Failed to parse output. Returning None.\n",
      "Evaluating:  82%|████████▏ | 41/50 [00:39<00:10,  1.12s/it]Failed to parse output. Returning None.\n",
      "Failed to parse output. Returning None.\n",
      "Evaluating:  86%|████████▌ | 43/50 [00:40<00:06,  1.06it/s]Failed to parse output. Returning None.\n",
      "Failed to parse output. Returning None.\n",
      "Evaluating:  90%|█████████ | 45/50 [00:42<00:05,  1.06s/it]Failed to parse output. Returning None.\n",
      "Evaluating:  92%|█████████▏| 46/50 [00:44<00:04,  1.21s/it]Failed to parse output. Returning None.\n",
      "Evaluating:  94%|█████████▍| 47/50 [00:46<00:04,  1.60s/it]Failed to parse output. Returning None.\n",
      "Evaluating:  96%|█████████▌| 48/50 [00:46<00:02,  1.17s/it]Failed to parse output. Returning None.\n",
      "Evaluating: 100%|██████████| 50/50 [00:48<00:00,  1.04it/s]\n",
      "c:\\Users\\TanmayRaju\\miniconda3\\envs\\genchatbot\\lib\\site-packages\\ragas\\evaluation.py:299: RuntimeWarning: Mean of empty slice\n",
      "  value = np.nanmean(self.scores[cn])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': nan, 'answer_relevancy': 0.7483, 'context_recall': 1.0000, 'context_precision': 1.0000, 'answer_correctness': 0.3779}\n"
     ]
    }
   ],
   "source": [
    "# testing evalframework V2\n",
    "scoreoutputv2 = eval_frameworkv2(filepath=\"C:/Users/TanmayRaju/Documents/GitHub/AdvRAG/new/data/LLM_Final.pdf\", groundtruthdataset=\"C:/Users/TanmayRaju/Documents/GitHub/AdvRAG/new/data/customphase2data.csv\", customchain=qa_advanced, myllm=chat_llm)\n",
    "print(scoreoutputv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for generating question for evaluation df\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "def testdf_generator(myllm, testsize ):\n",
    "\n",
    "    # Load your doc\n",
    "    loader1 = PyPDFLoader(r\"C:\\Users\\TanmayRaju\\Documents\\GitHub\\AdvRAG\\new\\data\\2016-Apr-26-AAPL.pdf\")\n",
    "    loader2 = PyPDFLoader(r\"C:\\Users\\TanmayRaju\\Documents\\GitHub\\AdvRAG\\new\\data\\2017-Aug-01-AAPL.pdf\")\n",
    "    loader3 = PyPDFLoader(r\"C:\\Users\\TanmayRaju\\Documents\\GitHub\\AdvRAG\\new\\data\\2018-Feb-01-AAPL.pdf\")\n",
    "    loader4 = PyPDFLoader(r\"C:\\Users\\TanmayRaju\\Documents\\GitHub\\AdvRAG\\new\\data\\2019-Apr-30-AAPL.pdf\")\n",
    "    loader5 = PyPDFLoader(r\"C:\\Users\\TanmayRaju\\Documents\\GitHub\\AdvRAG\\new\\data\\2020-Apr-30-AAPL.pdf\")\n",
    "\n",
    "    document1 = loader1.load()\n",
    "    document2 = loader2.load()\n",
    "    document3 = loader3.load()\n",
    "    document4 = loader4.load()\n",
    "    document5 = loader5.load()\n",
    "\n",
    "    # Document Splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 1000,\n",
    "        chunk_overlap = 200\n",
    "    )\n",
    "    documents1 = text_splitter.split_documents(document1)\n",
    "    documents2 = text_splitter.split_documents(document2)\n",
    "    documents3 = text_splitter.split_documents(document3)\n",
    "    documents4 = text_splitter.split_documents(document4)\n",
    "    documents5 = text_splitter.split_documents(document5)\n",
    "    #\n",
    "    generator_llm = myllm\n",
    "    critic_llm = myllm\n",
    "    embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "    #\n",
    "    generator = TestsetGenerator.from_langchain(\n",
    "        generator_llm,\n",
    "        critic_llm,\n",
    "        embeddings\n",
    "    )\n",
    "    #\n",
    "    testset1 = generator.generate_with_langchain_docs(documents1, test_size=testsize, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})\n",
    "    testset2 = generator.generate_with_langchain_docs(documents2, test_size=testsize, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})\n",
    "    testset3 = generator.generate_with_langchain_docs(documents3, test_size=testsize, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})\n",
    "    testset4 = generator.generate_with_langchain_docs(documents4, test_size=testsize, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})\n",
    "    testset5 = generator.generate_with_langchain_docs(documents5, test_size=testsize, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})\n",
    "\n",
    "    testset1 = testset1.to_pandas()\n",
    "    testset2 = testset2.to_pandas()\n",
    "    testset3 = testset3.to_pandas()\n",
    "    testset4 = testset4.to_pandas()\n",
    "    testset5 = testset5.to_pandas()\n",
    "\n",
    "     # Concatenate the DataFrames\n",
    "    evaldf = pd.concat([testset1, testset2, testset3, testset4, testset5], ignore_index=True)\n",
    "\n",
    "    # Save the combined dataset to a new CSV file\n",
    "    evaldf.to_csv(r'C:\\Users\\TanmayRaju\\Documents\\GitHub\\AdvRAG\\new\\data\\combined_testset.csv', index=False)\n",
    "\n",
    "    print(\"Saved final evaldf\")\n",
    "\n",
    "\n",
    "eval = testdf_generator(myllm=chat_llm, testsize=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing our evalframework function\n",
    "def allfile(filepath, customchain, myllm, testsize ):\n",
    "\n",
    "    # Load your doc\n",
    "    loader = DirectoryLoader(filepath, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Document Splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 1000,\n",
    "        chunk_overlap = 200\n",
    "    )\n",
    "    documents = text_splitter.split_documents(documents)\n",
    "    #\n",
    "    generator_llm = myllm\n",
    "    critic_llm = myllm\n",
    "    embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "    #\n",
    "    generator = TestsetGenerator.from_langchain(\n",
    "        generator_llm,\n",
    "        critic_llm,\n",
    "        embeddings\n",
    "    )\n",
    "    #\n",
    "    testset = generator.generate_with_langchain_docs(documents, test_size=testsize, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})\n",
    "\n",
    "    test_df = testset.to_pandas()\n",
    "    test_questions = test_df[\"question\"].values.tolist()\n",
    "    test_groundtruths = test_df[\"ground_truth\"].values.tolist()\n",
    "\n",
    "    # Generate responses using our Advanced RAG pipeline using the questions we’ve generated.\n",
    "    adv_answers = []\n",
    "    adv_contexts = []\n",
    "\n",
    "    for question in test_questions:\n",
    "        response = customchain.invoke({\"query\" : question})\n",
    "        adv_answers.append(response[\"result\"])\n",
    "        adv_contexts.append([context.page_content for context in response['source_documents']])\n",
    "\n",
    "    #wrap into huggingface dataset\n",
    "    response_dataset_advanced_retrieval = Dataset.from_dict({\n",
    "        \"question\" : test_questions,\n",
    "        \"answer\" : adv_answers,\n",
    "        \"contexts\" : adv_contexts,\n",
    "        \"ground_truth\" : test_groundtruths\n",
    "    })\n",
    "\n",
    "    metrics = [\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "        context_precision,\n",
    "        answer_correctness,\n",
    "    ]\n",
    "\n",
    "    advanced_retrieval_results = evaluate(response_dataset_advanced_retrieval, metrics, llm=myllm, embeddings=embeddings, raise_exceptions=False)\n",
    "    \n",
    "    return advanced_retrieval_results\n",
    "\n",
    "scoreoutput = allfile(filepath=\"data\", customchain=qa_advanced, myllm=chat_llm, testsize=1)\n",
    "print(scoreoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(\"data\", glob=\"*.docx\", loader_cls=PyPDFLoader)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
